'''
 * Copyright 2024 NXP
 * All rights reserved.
 *
 * SPDX-License-Identifier: BSD-3-Clause
'''
'''
 This script runs inference on images located in a directory using a TensorFlow Lite model.
 It creates a database of the generated embeddings in a header file ready to be imported to the IDE, a person can 
 be added to the database without regenerating the whole file.
 
 The script supports command-line arguments for specifying the paths to the images directory, the TFLite model and the 
 path to the image of the person to be added [optional].

 To use this script, provide the images folder path and the TFLite model path via command-line arguments:
 python3 generate_database_header_file.py -dir /path/to/imagesfolder  -M /path/to/model.tflite -Img /path/to/image[optional]
'''
import os
import cv2
import argparse
import tensorflow as tf
import numpy as np

# Inference function that takes the image and the model path as parameters
# and returns the output embeddings from the inference done with our model
def run_inference(img, model_path):
    # Load the model and allocate tensors
    interpreter = tf.lite.Interpreter(model_path=model_path)
    interpreter.allocate_tensors()

    # Get input and output tensor details
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    input_shape = input_details[0]["shape"]

    # Get quantization details crucial for quantization of input and dequantization of output
    input_scale, input_zero_point = input_details[0]["quantization"]
    output_scale, output_zero_point = output_details[0]["quantization"]

    # Preprocess the image (uint8)to match model requirements (int8)
    image = cv2.resize(img, (input_shape[1], input_shape[2])) 
    image = image[None, ...]  # Add batch dimension
    image = (image / input_scale + input_zero_point).astype(np.int8)  # Quantization of input from float to int8

    # Set input tensor and Run inference
    interpreter.set_tensor(input_details[0]["index"], image)
    interpreter.invoke()

    # Retrieve the output from the output tensor and dequantization of output based on parameters from int8 to float
    output = (interpreter.get_tensor(output_details[0]['index']) - output_zero_point) * output_scale

    return output

def header_creation(saved_directory, model_path,image_path=None):
    data = {}  # dictionary used to store embeddings generated by our model with their corresponding names
    model_output = {}  # dictionary used to store name and embeddings of the added person
    num_people = 0
    header_path = 'embeddings_database.h'

    if not os.path.exists(header_path):
        # Iterate over each file in the directory
        for file_name in os.listdir(saved_directory):
            # Check if the file is an image
            if file_name.endswith((".jpg", ".jpeg", ".png")):
                img = cv2.imread(os.path.join(saved_directory, file_name))
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                num_people += 1
                # Use our model to extract embeddings
                embedding = run_inference(img, model_path)
                if embedding is not None:
                    # Extract person's name from image file name
                    name = os.path.splitext(file_name)[0]
                    # Add the embedding and name
                    data[name] = embedding[0]

        # Write embeddings and corresponding names to a header file
        with open(header_path, 'w') as f:
            header_first = f""" 
#ifndef EMBEDDING_H
#define EMBEDDING_H \n
#include <stdint.h>
#include <mpp_config.h>\n
#define SIZE_EMBEDDING 256 
#define NUM_PEOPLE {num_people} \n
struct _person {{
    char name[MAX_STR_SIZE+1];
    const float embedding[SIZE_EMBEDDING];
}} person;\n
#if NUM_PEOPLE > MAX_PEOPLE\n     
#error "could not generate embeddings: Number of images exceeds maximum number allowed"      
#else\n
static const struct Person Embedding_database[NUM_PEOPLE] =
 {{
"""
            header_embeddings = '\n'.join(f'    {{"{name}",{{{", ".join(f"{val:.6f}" for val in embedding)}}}}},' for name, embedding in data.items())
            header_content = f"""{header_first}
{header_embeddings}
//EOT\n
}};\n
#endif
#endif // EMBEDDING_H
"""
        with open(header_path, 'w') as f:
            f.write(header_content)
            print("Header File generated successfully")
    else:
        # Check if the file exists and an image is provided to the script.
        # the person will be added to the file without the need to regenerate the entire file.
        if image_path:
            img = cv2.imread(image_path)
            num_people += 1
            embedding = run_inference(img, model_path)
            if embedding is not None:
                # Extract person's name from image file name
                name = os.path.splitext(image_path)[0]
                model_output[name] = embedding[0]
            # Add the embedding and name
            with open(header_path, 'r') as f:
                data = f.readlines()
                for i, line in enumerate(data):
                    if line.strip().startswith('#define NUM_PEOPLE'):
                        num_people = int(data[i].split()[-1]) + 1
                        data[i] = f"#define NUM_PEOPLE {num_people}\n"
                    if line.strip().startswith("//EOT"):
                        for name, embedding in model_output.items():
                            data[i-1] = '    {' + f'"{name}", '+'{'
                            for val in embedding:
                                data[i-1] += f'{val:.6f}, '
                            data[i-1] += '}},\n\n'
            with open(header_path, 'w') as f:
                f.writelines(data)
                print("Person added successfully")
        else:
            print("MISSING: Image path not specified")
    return header_path

if __name__ == "__main__":
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument("-dir", "--image_directory", type=str, required=True, help="Path to the input images")
    parser.add_argument("-M", "--model_path", type=str, required=True, help="Path to the model")
    parser.add_argument("-Img", "--image_path", type=str, required=False, help="Path to the image to be added to database")

    args = parser.parse_args()  # Parse arguments from the command line
    header_creation(args.image_directory, args.model_path, args.image_path)
